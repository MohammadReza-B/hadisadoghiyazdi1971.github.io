---
layout: persian # ุง single ุจุง ฺฉูุงุณ rtl-layout
classes: wide rtl-layout
dir: rtl
title: "ุฎูุดู ุจูุฏ ุชุตุงูุฑ"
permalink: /teaching/studenteffort/patterneffort/image_clustering/
author_profile: true

header:
  overlay_image: "/assets/images/background.jpg"
  overlay_filter: 0.3
  overlay_color: "#5e616c"
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
---

# ุงุณุชุฎุฑุงุฌ ูฺฺฏ ุงุฒ ุชุตุงูุฑ ู ุฎูุดู ุจูุฏ

<div  dir="rtl">
<p >

<p> ููุณูุฏู : ูพุงุฑุณุง ุณู ฺ</p>
  <a href="mailto:p.sinichi@gmail.com">
p.sinichi@gmail.com  </a>
</p>
<p >
  ุฏุงูุดฺฏุงู ูุฑุฏูุณ ูุดูุฏ
  <br>
  ูููุฏุณ ฺฉุงููพูุชุฑ
</p>

</div>

<div dir="rtl">

## ููุฑุณุช ูุทุงูุจ

<ul>
  <li><a href="#ููุฏูู">ููุฏูู</a></li>
  <li><a href="#ุงุฏฺฏุฑ-ุจุฏูู-ูุธุงุฑุช-ู-ุฎูุดูุจูุฏ">ุงุฏฺฏุฑ ุจุฏูู ูุธุงุฑุช ู ุฎูุดูโุจูุฏ</a></li>
  <li><a href="#ุงููุช-ุงุณุชุฎุฑุงุฌ-ูฺฺฏ">ุงููุช ุงุณุชุฎุฑุงุฌ ูฺฺฏ</a></li>
  <li><a href="#ุดุจฺฉู-ูุง-ุนุตุจ-cnn-ู-ูุฏู-vgg16">ุดุจฺฉู ูุง ุนุตุจ CNN ู ูุฏู VGG16</a></li>
  <li><a href="#ุชูุงุจุน-ุถุฑุฑ">ุชูุงุจุน ุถุฑุฑ</a>
    <ul>
      <li><a href="#1-ุชุงุจุน-ุถุฑุฑ-ูุฑุจุน-square-loss--l2">1. ุชุงุจุน ุถุฑุฑ ูุฑุจุน Square Loss / L2</a></li>
      <li><a href="#2-ุชุงุจุน-ุถุฑุฑ-ูุทูู-absolute-loss--l1">2. ุชุงุจุน ุถุฑุฑ ูุทูู Absolute Loss / L1</a></li>
      <li><a href="#3-ุชุงุจุน-huber-loss">3. ุชุงุจุน Huber Loss</a></li>
      <li><a href="#4-ุชุงุจุน-pseudo-huber-loss">4. ุชุงุจุน Pseudo-Huber Loss</a></li>
      <li><a href="#5-ุชุงุจุน-correntropy-loss">5. ุชุงุจุน Correntropy Loss</a></li>
      <li><a href="#6-ุชุงุจุน-epsilon-insensitive-loss">6. ุชุงุจุน Epsilon-Insensitive Loss</a></li>
    </ul>
  </li>
  <li><a href="#ุงุณุชูุงุฏู-ุงุฒ-ุชูุงุจุน-ุถุฑุฑ-ุจุฑุง-ุฎูุดู-ุจูุฏ">ุงุณุชูุงุฏู ุงุฒ ุชูุงุจุน ุถุฑุฑ ุจุฑุง ุฎูุดู ุจูุฏ</a>
    <ul>
      <li><a href="#1-ุฑุงูุญููุง-ุชุญูู-analytical-solutions">1. ุฑุงูโุญูโูุง ุชุญูู</a></li>
      <li><a href="#2-ุจูููุณุงุฒ-ุนุฏุฏ-numerical-optimization">2. ุจูููโุณุงุฒ ุนุฏุฏ</a></li>
    </ul>
  </li>
  <li><a href="#ุชูุงุจุน-ุจุง-ุฑุงู-ุญู-ูุญุงุณุจุงุช">ุชูุงุจุน ุจุง ุฑุงู ุญู ูุญุงุณุจุงุช</a>
    <ul>
      <li><a href="#ุชุงุจุน-l2-loss-square-loss--mean">ุชุงุจุน L2 Loss (Square Loss) โ Mean</a></li>
    </ul>
  </li>
  <li><a href="#ูพุงุฏู-ุณุงุฒ-ุฎูุดู-ุจูุฏ-ุจุง-ุงุณุชูุงุฏู-ุงุฒ-ุชูุงุจุน-ุถุฑุฑุฑ-ูุฎุชูู">ูพุงุฏู ุณุงุฒ ุฎูุดู ุจูุฏ ุจุง ุงุณุชูุงุฏู ุงุฒ ุชูุงุจุน ุถุฑุฑุฑ ูุฎุชูู</a>
    <ul>
      <li><a href="#ููุฏ-ฺฉุฑุฏู-ฺฉุชุงุจุฎุงูู-ูุง-ููุฑุฏ-ุงุณุชูุงุฏู-">ููุฏ ฺฉุฑุฏู ฺฉุชุงุจุฎุงูู ูุง ููุฑุฏ ุงุณุชูุงุฏู</a></li>
      <li><a href="#ููุฏ-ฺฉุฑุฏู-ูุฏู-vgg16-ุจุฑุง-ุงุณุชุฎุฑุงุฌ-ูฺฺฏ">ููุฏ ฺฉุฑุฏู ูุฏู vgg16 ุจุฑุง ุงุณุชุฎุฑุงุฌ ูฺฺฏ</a></li>
      <li><a href="#ุงุณุฎุฑุงุฌ-ูฺฺฏ-ุงุฒ-ูุฌููุนู-ุฏุงุฏู">ุงุณุฎุฑุงุฌ ูฺฺฏ ุงุฒ ูุฌููุนู ุฏุงุฏู</a></li>
      <li><a href="#ุชุนุฑู-ุชูุงุจุน-ุถุฑุฑ-ุฏุฑ-ฺฉุฏ">ุชุนุฑู ุชูุงุจุน ุถุฑุฑ ุฏุฑ ฺฉุฏ</a></li>
    </ul>
  </li>
  <li><a href="#ุงูฺฏูุฑุชู-ุฎูุดู-ุจูุฏ">ุงูฺฏูุฑุชู ุฎูุดู ุจูุฏ</a>
    <ul>
      <li><a href="#ูพุงุฏู-ุณุงุฒ">ูพุงุฏู ุณุงุฒ</a></li>
    </ul>
  </li>
  <li><a href="#ูุชุงุฌ-ุฎูุดู-ุจูุฏ">ูุชุงุฌ ุฎูุดู ุจูุฏ</a>
    <ul>
      <li><a href="#ุชุงุจุน-l2">ุชุงุจุน L2</a></li>
      <li><a href="#ุชุงุจุน-l1">ุชุงุจุน L1</a></li>
      <li><a href="#ุชุงุจุน-huber">ุชุงุจุน Huber</a></li>
      <li><a href="#ุชุงุจุน-pseudo-huber">ุชุงุจุน Pseudo-Huber</a></li>
      <li><a href="#ุชุงุจุน-correntropy">ุชุงุจุน Correntropy</a></li>
      <li><a href="#ุชุงุจุน-epsilon-insensitive">ุชุงุจุน Epsilon-Insensitive</a></li>
    </ul>
  </li>
  <li><a href="#ููุงุจุน">ููุงุจุน</a></li>
</ul>

---

</div>

## ููุฏูู ู ุชุนุฑู ูุณุฆูู

ุฏุฑ ุงู ูพุฑูฺูุ ุจู ุจุฑุฑุณ ู ูพุงุฏูโุณุงุฒ ุฑูุดโูุง ูุฎุชูู ุฎูุดูโุจูุฏ ุชุตุงูุฑ ุจุง ุงุณุชูุงุฏู ุงุฒ ูฺฺฏ ูุง ุงุณุชุฎุฑุงุฌ ุดุฏู ุงุฒุดุจฺฉู ูุง ุนุตุจ ุนูู ูโูพุฑุฏุงุฒู. ูุฏู ุงุตู ุงู ุงุณุช ฺฉู ุชุตุงูุฑ ุฑุง ุจุฑ ุงุณุงุณ ูุญุชูุง ุจุตุฑโุดุงู ุจู ฺฏุฑููโูุง ูุนูุงุฏุงุฑ ุชูุณู ฺฉูู. ุจุฑุง ุงู ููุธูุฑุ ุงุจุชุฏุง ุงุฒ ุดุจฺฉู ุนุตุจ ูพุดโุขููุฒุดโุฏุฏู VGG16 ุจุฑุง ุงุณุชุฎุฑุงุฌ ูฺฺฏโูุง ุชุตุงูุฑ ุงุณุชูุงุฏู ูโฺฉูู. ุณูพุณ ุจุง ุจฺฉุงุฑฺฏุฑ ุชูุงุจุน ุถุฑุฑ ูุฎุชูู (ุงุฒ ุฌููู L1ุ L2ุ Huberุ Correntropy ู ...) ู ุชฺฉูฺฉโูุง ุจูููโุณุงุฒ ุนุฏุฏุ ุฎูุดูโุจูุฏ ุฑุง ุงูุฌุงู ูโุฏูู.

ุณูพุณ ุจุฑุง ุฏุฑฺฉ ุจูุชุฑ ุงุฒ ูุชุงุฌ ูุฑฺฉุฒ ุฎูุดู ูุง ฺฉู ูุดุงู ุฏููุฏู ุชุตุงูุฑ ููุฌูุฏ ุฏุฑ ุฏุงุฏู ูุง ูุง ูุณุชูุฏ ุฑุง ููุงุด ู ุฏูู. ุงู ุชุตุงูุฑ (ูุฑุงฺฉุฒ ุฎูุดู) ููุงุท ุฏุฑ ูุถุง ูฺฺฏ ูุง ูุง ูุณุชูุฏ ฺฉู ฺฉูุชุฑู ูุฌููุน ูุงุตูู ุฑุง ุจุง ุณุงุฑ ููุงุท ุฏุงุฑูุฏ.

ุงู ูพุฑูฺู ูุดุงู ูโุฏูุฏ ฺฉู ุงูุชุฎุงุจ ุชุงุจุน ุถุฑุฑ ููุงุณุจ ฺฺฏููู ูโุชูุงูุฏ ุจุฑ ูุชุงุฌ ุฎูุดูโุจูุฏ ุชุฃุซุฑ ุจฺฏุฐุงุฑุฏ. ููฺูู ุชูุงูุช ุจู ุฑูุดโูุง ุชุญูู ู ุจูููโุณุงุฒ ุนุฏุฏ ุฑุง ุจุฑุง ุงูุชู ูุฑุงฺฉุฒ ุจููู ุฎูุดูโูุง ุจุฑุฑุณ ูโฺฉูู.

## ุงุฏฺฏุฑ ุจุฏูู ูุธุงุฑุช ู ุฎูุดูโุจูุฏ

ุงุฏฺฏุฑ ุจุฏูู ูุธุงุฑุช ุจู ุชฺฉูฺฉโูุง ุงุทูุงู ูโุดูุฏ ฺฉู ุจุฏูู ูุงุฒ ุจู ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑุ ุงูฺฏููุง ู ฺฏุฑููโุจูุฏโูุง ุฑุง ุฏุฑ ุฏุงุฏูโูุง ฺฉุดู ูโฺฉููุฏ. ุฎูุดูโุจูุฏ ฺฉ ุงุฒ ุฑุงุฌโุชุฑู ุฑูุดโูุง ุงุฏฺฏุฑ ุจุฏูู ูุธุงุฑุช ุงุณุช ฺฉู ุฏุงุฏูโูุง ุฑุง ุจู ฺฏุฑููโูุง (ุฎูุดูโูุง) ุชูุณู ูโฺฉูุฏ ุจู ฺฏูููโุง ฺฉู ุนูุงุตุฑ ุฏุฑูู ูุฑ ุฎูุดู ุดุจุงูุช ุจุดุชุฑ ุจู ฺฉุฏฺฏุฑ ูุณุจุช ุจู ุนูุงุตุฑ ุฎูุดูโูุง ุฏฺฏุฑ ุฏุงุดุชู ุจุงุดูุฏ. ุจุง ุงุนูุงู ุฎูุดูโุจูุฏ ุจุฑ ุฑู ูฺฺฏโูุง ุงุณุชุฎุฑุงุฌโุดุฏู ุงุฒ ุชุตุงูุฑุ ูโุชูุงูู ุจู ุทูุฑ ุฎูุฏฺฉุงุฑ ุชุตุงูุฑ ุฑุง ุจุฑ ุงุณุงุณ ูุญุชูุง ุจุตุฑโุดุงู ุจู ฺฏุฑููโูุง ูุนูุงุฏุงุฑ ุณุงุฒูุงูุฏู ฺฉูู.

ุงู ูพุฑูฺู ุงูฺฏูุฑุชูโูุง ุฎูุดูโุจูุฏ ุชุนููโุงูุชู ุฑุง ุจุง ุงุณุชูุงุฏู ุงุฒ ุชูุงุจุน ุถุฑุฑ ูุฎุชูู ูพุงุฏูโุณุงุฒ ูโฺฉูุฏ ฺฉู ุงูฺฉุงู ฺฏุฑููโุจูุฏ ุงูุนุทุงูโูพุฐุฑ ู ููุงูู ุชุตุงูุฑ ุฑุง ูุฑุงูู ูโุขูุฑุฏ. ูุชุงุฌ ุจูโุฏุณุชโุขูุฏู ุจูุด ุฏุฑุจุงุฑู ุณุงุฎุชุงุฑ ูุฌููุนู ุฏุงุฏู ุชุตูุฑ ุงุฑุงุฆู ูโุฏูุฏ ู ูุฏุฑุช ุชุฑฺฉุจ ุงุณุชุฎุฑุงุฌ ูฺฺฏ ุนูู ุจุง ุงุฏฺฏุฑ ุจุฏูู ูุธุงุฑุช ุฑุง ูุดุงู ูโุฏูุฏ.

## ุงููุช ุงุณุชุฎุฑุงุฌ ูฺฺฏ

ุชุตุงูุฑ ุจู ุทูุฑ ฺฉู ุฏุงุฏูโูุง ุจุง ุงุจุนุงุฏ ุจุงูุง ูุณุชูุฏ ฺฉู ูุนูููุงู ุดุงูู ูุฒุงุฑุงู ุง ููููโูุง ูพฺฉุณู ูโุจุงุดูุฏ. ุงุณุชูุงุฏูโ ูุณุชูู ุงุฒ ุงู ููุงุฏุฑ ูพฺฉุณู ุจุฑุง ูุธุงู ุงุฏฺฏุฑ ูุงุดูุ ูุงฺฉุงุฑุขูุฏ ู ุจูโูุฏุฑุช ูุคุซุฑ ุงุณุชุ ุฒุฑุง ุงู ููุงุฏุฑ ุงูฺฏููุง ุง ูุญุชูุง ูุนูุง ุฒุฑู ุชุตูุฑ ุฑุง ุจูโุฎูุจ ููุงุด ููโุฏููุฏ.
ุงุณุชุฎุฑุงุฌ ูฺฺฏุ ุชุตุงูุฑ ุฎุงู ุฑุง ุจู ููุงุดโูุง ูุดุฑุฏู ู ุขฺฏุงูุงููโุง ุชุจุฏู ูโฺฉูุฏ ฺฉู ุงุทูุงุนุงุช ุจุตุฑ ุงุณุงุณ ุฑุง ุฎูุงุตู ูโุณุงุฒูุฏ. ุงู ฺฉุงุฑ ุจุงุนุซ ูโุดูุฏ ูุธุงู ุจุนุฏ ูุงููุฏ ุทุจููโุจูุฏุ ุฎูุดูโุจูุฏ ู ุจุงุฒุงุจุ ููุงููโุชุฑ ู ุงุฒ ูุธุฑ ูุญุงุณุจุงุช ุงูฺฉุงูโูพุฐุฑุชุฑ ุดููุฏ.

## ุดุจฺฉู ูุง ุนุตุจ CNN ู ูุฏู VGG16

ุดุจฺฉูโูุง ุนุตุจ ฺฉุงููููุดู ุง ุจู ุงุฎุชุตุงุฑ (CNN) ฺฉ ุงุฒ ุงููุงุน ูุฏูโูุง ุงุฏฺฏุฑ ุนูู ูุณุชูุฏ ฺฉู ุจูโุทูุฑ ุฎุงุต ุจุฑุง ุฏุงุฏูโูุง ุชุตูุฑ ุทุฑุงุญ ุดุฏูโุงูุฏ. ุงู ุดุจฺฉูโูุง ุงุฒ ูุงูโูุง ฺฉุงููููุดู ุจุฑุง ุงุฏฺฏุฑ ุฎูุฏฺฉุงุฑ ูฺฺฏโูุง ุณูุณููโูุฑุงุชุจ )ุจุฒุฑฺฏ ุจู ฺฉูฺฺฉ) ุงุณุชูุงุฏู ูโฺฉููุฏ. ุงุฒ ูุจูโูุง ู ุงูฺฏููุง ุณุงุฏู ฺฏุฑูุชู ุชุง ุงุดฺฉุงู ู ุงุฌุณุงู ูพฺุฏูโุชุฑ. VGG16 ฺฉ ูุนูุงุฑ ูุนุฑูู ุงุฒ ููุน CNN ุงุณุช ฺฉู ุจู ุฏูู ุณุงุฏฺฏ ู ฺฉุงุฑุง ุจุงูุง ุดูุงุฎุชู ูโุดูุฏ. ุงู ูุฏู ุงุฒ ฑถ ูุงู ุจุง ูุฒูโูุง ูุงุจู ุงุฏฺฏุฑ ุชุดฺฉู ุดุฏู ู ุงุฒ ููุชุฑูุง ฺฉุงููููุดู ฺฉูฺฺฉ (ณรณ) ุงุณุชูุงุฏู ูโฺฉูุฏ. VGG16 ุจุฑ ุฑู ูุฌููุนูโุฏุงุฏูโ ุจุฒุฑฺฏ ImageNet ฺฉู ุดุงูู ูููู ูุง ุชุตูุฑ ุฑูุฒูุฑู ุงุฒ ูพุด ุขููุฒุด ุฏุงุฏู ุดุฏู ุงุณุช ู ุจู ููู ุฏูู ูุงุฏุฑ ุงุณุช ูฺฺฏโูุง ุบู ู ูุงุจู ุชุนูู ุฑุง ุงุฒ ุชุตุงูุฑ ุฌุฏุฏ ุงุณุชุฎุฑุงุฌ ฺฉูุฏ.

ุฏุฑ ุงู ูพุฑูฺูุ ุงุฒ VGG16 ุจูโุนููุงู ุงุณุชุฎุฑุงุฌโฺฉููุฏูโ ูฺฺฏโูุง (Feature Extractor) ุงุณุชูุงุฏู ูโุดูุฏ. ุจูโุฌุง ุงุณุชูุงุฏู ุงุฒ ูุฏู ุจุฑุง ุทุจููโุจูุฏุ ุฎุฑูุฌ ูุงูโูุง ฺฉุงููููุดู ุขู ุจุฑุง ุจูโุฏุณุชโุขูุฑุฏู ุจุฑุฏุงุฑ ูฺฺฏ ูุฑ ุชุตูุฑ ุจู ฺฉุงุฑ ฺฏุฑูุชู ูโุดูุฏ. ุงู ุจุฑุฏุงุฑูุง ูููโุชุฑู ูฺฺฏโูุง ุจุตุฑ ุชุตุงูุฑ ุฑุง ุฏุฑ ุจุฑ ูโฺฏุฑูุฏ ู ูุจูุง ุจุฑุง ุฎูุดูโุจูุฏ ุฏุงุฏูโูุง ูุฑุงูู ูโฺฉููุฏ.

ุดุจฺฉูโูุง ฺฉุงููููุดู ุงุณุงุณุงู ุจุง ยซููุชุฑูุง / ฺฉุฑููโูุงยป ฺฉุงุฑ ูโฺฉููุฏ. ููุชุฑ ฺฉ ูุงุชุฑุณ ฺฉูฺฺฉ (ูุซูุงู 
3
ร
3
  ุง 5ร5) ุงุณุช ฺฉู ุฑู ุชุตูุฑ ุญุฑฺฉุช ูโฺฉูุฏ ู ุฏุฑ ูุฑ ูููุนุชุ ุจุง ุจุฎุด ุงุฒ ุชุตูุฑ ุถุฑุจ ุฏุงุฎู ุงูุฌุงู ูโุฏูุฏ. ุฎุฑูุฌ ุงู ุนููุงุช ฺฉ ููุดู ูฺฺฏ (Feature Map) ุงุณุช ฺฉู ูุดุงู ูโุฏูุฏ ยซฺฉ ุงูฺฏู ุฎุงุตยป ุฏุฑ ฺฉุฌุง ุชุตูุฑ ูุฌูุฏ ุฏุงุฑุฏ.


 

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/image.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ููุชุฑ ูุง ฺฉุงููููุดู
</div>

<br>

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/image-1.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ูุฑุงูุฏ  ุงุณุชุฎุฑุงุฌ ูฺฺฏ
</div>

<br>

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/fx-image2.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ุงุณุชูุงุฏู ุงุฒ ุดุจฺฉู ุนุตุจ vgg16 ุจุฑุง ุงุณุชุฎุฑุงุฌ ูฺฺฏ

</div>

<br>
<br>
ุจุฑุง ุฏุฑฺฉ ุจูุชุฑ ูฺฺฏ ูุง ูุชูุงู ุชุนุฏุงุฏ ุงุฒ ูฺฺฏ ูุง ุงุณุชุฎุฑุงุฌ ุดุฏู ุงุฒ ุชุตุงูุฑ ุฑุง ูุดุงูุฏู ฺฉุฑุฏ

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/org_ant.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ุชุตูุฑ ููููู ููุฑุฏ ุงุณุชูุงุฏู ุจุฑุง ุงุณุชุฎุฑุงุฌ ูฺฺฏ
</div>

<br>
<br>
<br>

ุฏุฑ ุชุตูุฑ ุฒุฑ ูุชูุงู ุชุนุฏุงุฏ ุงุฒ ูฺฺฏ ูุง ุงุณุชุฎุฑุงุฌ ุดุฏู ุฑุง ูุดุงูุฏู ฺฉุฑุฏ :

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/layer_1_overview.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
</div>
<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/layer_1_overview.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ููููู ุงุฒ ูฺฺฏ ูุง ุงุณุชุฎุฑุงุฌ ุดุฏู ุงุฒ ุดุจฺฉู ุนุตุจ CNN</div>

<br>

```python
import torch
import torchvision.models as models
import torchvision.transforms as T
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
#  Load VGG16
vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features.eval()
layers_to_tap = [1,2,3, 8, 15, 22, 29]
features = {}
def save_activation(name):
    def hook(module, inp, out):
        features[name] = out.detach().cpu()
    return hook
for idx in layers_to_tap:
    vgg[idx].register_forward_hook(save_activation(f"layer_{idx}"))
#  Preprocess
tfms = T.Compose([
    T.Resize(256),
    T.CenterCrop(224),
    T.ToTensor(),
    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
])
img_path = ""
img = Image.open(img_path).convert("RGB")
plt.imshow(img)
plt.axis(False)
plt.show()
x = tfms(img).unsqueeze(0)
with torch.no_grad():
    vgg(x)
def normalize_channel(arr):
    arr = arr - arr.mean()
    arr = arr / (arr.std() + 1e-5)
    arr = arr * 64 + 128
    return np.clip(arr, 0, 255).astype("uint8")
channels_to_show = 8
for name, fmap in features.items():
    #[1, C, H, W]
    fmap = fmap[0]
    n = min(channels_to_show, fmap.shape[0])
    cols = 4
    rows = int(np.ceil(n / cols))
    plt.figure(figsize=(cols * 4.2, rows * 4.2))
    plt.suptitle(f"{name} โ feature maps", y=0.98, fontsize=12)
    for i in range(n):
        ax = plt.subplot(rows, cols, i + 1)
        chan = fmap[i].cpu().numpy()
        norm_img = normalize_channel(chan)
        ax.imshow(norm_img, cmap="viridis")
        ax.set_xticks([]); ax.set_yticks([])
        ax.set_title(f"ch {i}", fontsize=8)
    plt.tight_layout()
    plt.show()
    plt.close()
```

---

ุฏุฑ ุงู ูพุฑูฺู ูุฏู ูุง ุงุนูุงู ุฑูุด ูุง ูุฎุชูู ุจููู ุณุงุฒ ู ุชูุงุจุน ุถุฑุฑ ูุฎุชูู ุจุฑุง ุฎูุดู ุจูุฏ ุชุตุงูุฑ ุงุณุช

ุจู ุนููุงู ููููู ุฏุฑ ุงู ูุซุงู ุ ุงุฒ ุชุนุฏุงุฏ ุง ุชุตุงูุฑ ุญูุงูุงุช ุงุณุชูุงุฏู ูฺฉูู ู ุณุน ูฺฉูู ุจุง ุงุณุชูุงุฏู ุงุฒ ูฺฺฏ ูุง ุงุณุชุฎุฑุงุฌ ุดุฏู ุงุฒ ุขู ูุง ุ ุฎูุดู ุจูุฏ ุฑุง ุงูุฌุงู ุฏูู.

ุฏุฑ ุดฺฉู ุฒุฑ ฺูุฏ ููููู ุงุฒ ุชุตุงูุฑ ุฏุชุงุณุช ุฑุง ูุชูุงู ูุดุงูุฏู ฺฉุฑุฏ :

<div style="display: flex; justify-content: center; align-items: center; gap: 10px; flex-wrap: wrap;">
    <img src="/assets/patterneffort/ImageCluster/data_sample (3).jpg" alt="IPS1" style="width: 24%; height: auto; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/data_sample (1).jpg" alt="IPS1" style="width: 24%; height: auto; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/data_sample (2).jpg" alt="IPS1" style="width: 24%; height: auto; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/data_sample (4).jpg" alt="IPS1" style="width: 24%; height: auto; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ููููู ุง ุงุฒ ุชุตุงูุฑ ุฏุฑ ูุฌููุนู ุฏุงุฏู ูุง
</div>

# ุฏุงูููุฏ ุฏุงุฏู ูุง

ุงู ุฏุงุฏู ูุง ุฏุฑ ููฺฉ ุฒุฑ ูุงุจู ุฏุงูููุฏ ู ุจุงุดุฏ :โ

```
https://drive.google.com/file/d/1uPN3s1zBcmsl8oU_nOFG2MeWx4rM-Y2s/view?usp=sharing

```

# ุชูุงุจุน ุถุฑุฑ

ุฏุฑ ุงู ูุณูุช ุจู ูุนุฑู ุชูุงุจุน ุถุฑุฑ ฺฉู ุจุฑุง ุฎูุดู ุจูุฏ ุฏุฑ ุงู ุชูุฑู ุงุณุชูุงุฏู ูฺฉูู ุฎูุงูู ูพุฑุฏุงุฎุช :
ุจุฑุง ุงุทูุงุน ุจุดุชุฑ ู ูุญูู ุฏูู ุนูฺฉูุฑุฏ ูุฑ ุชุงุจุน ุจู ููฺฉ ูุง ุฒุฑ ูุฑุงุฌุนู ฺฉูุฏ

# ููุฑุณุช ุชูุงุจุน ุถุฑุฑ

  <nav aria-label="ููุฑุณุช ุชูุงุจุน ุถุฑุฑ">
    <ul>
      <li><a href="https://laboratorypatternrecognition.github.io/PatternRecognition_S/PR/Clustering/Clustering_1.html#square-loss">Square Loss (L2)</a></li>
      <li><a href="https://laboratorypatternrecognition.github.io/PatternRecognition_S/PR/Clustering/Clustering_1.html#absolute-loss">Absolute Loss (L1)</a></li>
      <li><a href="https://en.wikipedia.org/wiki/Huber_loss">Huber Loss</a></li>
      <li><a href="https://laboratorypatternrecognition.github.io/PatternRecognition_S/PR/Clustering/Clustering_1.html#pseudo-huber-loss">Pseudo-Huber Loss</a></li>
      <li><a href="https://laboratorypatternrecognition.github.io/PatternRecognition_S/PR/Clustering/Clustering_1.html#correntropy-loss">Correntropy Loss</a></li>
      <li><a href="https://laboratorypatternrecognition.github.io/PatternRecognition_S/PR/Clustering/Clustering_1.html#epsilon-insensitive-loss">Epsilon-Insensitive Loss</a></li>
    </ul>
  </nav>

---

# ุงุณุชูุงุฏู ุงุฒ ุชูุงุจุน ุถุฑุฑ ุจุฑุง ุฎูุดู ุจูุฏ

ุฏุฑ ูุณุฆููโ ุฎูุดูโุจูุฏุ ุจุงุฏ ยซูุฑฺฉุฒยป ูุฑ ุฎูุดู ุฑุง ุจุงุจู ฺฉู ูุฌููุน ุฒุงูโูุง ุฑุง ฺฉููู ฺฉูุฏ. ุจุณุชู ุจู ููุน ุชุงุจุน ุถุฑุฑ ุงู ฺฉุงุฑ ูโุชูุงูุฏ ุจู ฺฉ ุงุฒ ุฏู ุฑูุด ุฒุฑ ุงูุฌุงู ุดูุฏ:

---

#### 1. **ุฑุงูโุญูโูุง ุชุญูู (Analytical Solutions)**

ุจุฑุฎ ุชุงุจุนโูุง ุถุฑุฑ ูุฑููู ุฑุงุถ ูุดุฎุต ุจุฑุง ูุฑฺฉุฒ ุจููู ุฏุงุฑูุฏ:

<div dir="rtl">
ุจู ุนููุงู ูุซุงู ุชุงุจุน ุถุฑุฑ L2 ุฑุง ูุชูุงู ูุณุชูู ุจุง ูุงูฺฏู ุญุณุงุจ ฺฉุฑุฏ
<br>

</div>

$
\mu^* = \frac{1}{n}\sum_{i=1}^n x_i
$
<div dir="rtl">

<div dir="rtl">
ุจู ุนููุงู ูุซุงู ุชุงุจุน ุถุฑุฑ L1 ุฑุง ูุชูุงู ูุณุชูู ุจุง ูุงูู ุญุณุงุจ ฺฉุฑุฏ
<br>

</div>   
</div>

$\mu^* = \text{median}(x_1, x_2, \ldots, x_n)$


---

#### 2. ุจูููโุณุงุฒ ุนุฏุฏ (Numerical Optimization)

ุจุดุชุฑ ุชุงุจุนโูุง ุฒุงู ุฏฺฏุฑ (ูุซู Huberุ Correntropy ู ...) ูุฑููู ุจุณุชูโุง ุจุฑุง $\mu^*$ ูุฏุงุฑูุฏุ
ุจูุงุจุฑุงู ุจุงุฏ ุงุฒ ุฑูุดโูุง ุนุฏุฏ ุจุฑุง ุงูุชู ูุฑฺฉุฒ ุจููู ุงุณุชูุงุฏู ฺฉูู.
ุฏุฑ ุจุณุงุฑ ุงุฒ ุชูุงุจุน ุถุฑุฑุ ูุดุชูโฺฏุฑ ู ุจุฑุงุจุฑ ุตูุฑ ูุฑุงุฑ ุฏุงุฏู ุขู ููุฌุฑ ุจู ฺฉ ูุนุงุฏูู ุณุงุฏู ูุงููุฏ ูุงูฺฏู ุง ูุงูู ููโุดูุฏ. ุจูโุนุจุงุฑุช ุฏฺฏุฑุ ููุทูโุง ฺฉู ูุฌููุน ุถุฑุฑูุง ุฑุง ฺฉููู ูโฺฉูุฏุ ุฑุดูโ ฺฉ ูุนุงุฏููโ ุบุฑุฎุท ุง ุญุช ุบุฑูุดุชูโูพุฐุฑ ุงุณุช. ุจู ููู ุฏูู ููโุชูุงู ฺฉ ูุฑููู ุจุณุชู ุจุฑุง ูุฑฺฉุฒ ุฎูุดู ููุดุช ู ุจุงุฏ ุงุฒ ุฑูุดโูุง ุจูููโุณุงุฒ ุนุฏุฏ ุจุฑุง ูพุฏุง ฺฉุฑุฏู ููุฏุงุฑ ุจููู ุงุณุชูุงุฏู ฺฉุฑุฏ.

ุฏุฑ ุจูููโุณุงุฒ ุนุฏุฏุ ูุง ุชุงุจุน ุถุฑุฑ ุฑุง ูุงููุฏ ฺฉ ฺุดูโุงูุฏุงุฒ (Loss Landscape) ุฏุฑ ูุธุฑ ูโฺฏุฑู ฺฉู ูุฑ ููุทูโ ุขู ููุฏุงุฑ ุฎุทุง ุฑุง ูุดุงู ูโุฏูุฏ. ูุฏู ุงูฺฏูุฑุชู ุงู ุงุณุช ฺฉู ุจุง ุญุฑฺฉุช ุฏุฑ ุงู ฺุดูโุงูุฏุงุฒุ ููุทูโุง ุฑุง ูพุฏุง ฺฉูุฏ ฺฉู ฺฉูุชุฑู ููุฏุงุฑ ุฑุง ุฏุงุฑุฏ. ุงุฒ ุขูุฌุง ฺฉู ุดฺฉู ุงู ฺุดูโุงูุฏุงุฒ ุจุฑุง ุชูุงุจุน ูุฎุชูู ูุชูุงูุช ุงุณุชุ ุฑูุชุงุฑ ุงูฺฏูุฑุชู ู ููุทูโ ููุง ูุฒ ูุชูุงูุช ุฎูุงูุฏ ุจูุฏ.

---

**ูุญููโ ฺฉุงุฑ `scipy.optimize.minimize`:**

```python
result = minimize(objective_function, initial_guess, method='BFGS')
```

<div dir="rtl" style="text-align: right;">
- ุชุงุจุน ูุฏู (Objective Function): ุชุงุจุน ฺฉู ูโุฎูุงูู ฺฉููู ฺฉูู (ูุฌููุน ุฒุงูโูุง)  
- ุญุฏุณ ุงููู (Initial Guess): ููุทูู ุดุฑูุน ุฌุณุชโูุฌู (ูุนูููุงู ุงุฒ ูุงูฺฏู ุฏุงุฏูโูุง ุงุณุชูุงุฏู ูโุดูุฏ)  
- method='BFGS': ุงูฺฏูุฑุชู ูุจุชู ุจุฑ ฺฏุฑุงุฏุงู ฺฉู ูุฑุงุญู ุฒุฑ ุฑุง ุท ูโฺฉูุฏ:

1. ุงุฒ ุญุฏุณ ุงููู ุขุบุงุฒ ูโฺฉูุฏ
2. ฺฏุฑุงุฏุงู (ุฌูุช ุจุดุชุฑู ฺฉุงูุด) ุฑุง ูุญุงุณุจู ูโฺฉูุฏ
3. ุฏุฑ ุขู ุฌูุช ฺฉ ฺฏุงู ุจุฑูโุฏุงุฑุฏ
4. ุงู ูุฑุงูุฏ ุฑุง ุชุง ููฺฏุฑุง ุจู ุญุฏุงูู ุชฺฉุฑุงุฑ ูโฺฉูุฏ
</div>

#### ููุงุณู 2 ุฑูุด

<div dir="rtl" style="text-align: right;">
- ุชุญูู: ูุญุงุณุจูู ุณุฑุน ู ุฏููุ ุจุฏูู ุฎุทุง ุชูุฑุจ  
- ุนุฏุฏ: ฺฉูุฏุชุฑุ ุงูุง ุชููุง ฺฏุฒููู ููฺฉู ุฒูุงู ฺฉู ูุฑููู ุฌูุงุจ ูุดุฎุต ูุฏุงุฑุฏ
</div>

ุจู ุนููุงู ูุซุงู ฺฉ ููููู ุงุฒ ฺฉุงุฑฺฉุฑุฏ ุงู ุฑูุด ุฑุง ุจุฑุง ฺฉ ุชุงุจุน ุถุฑุฑ ูุชูุงู ูุดุงูุฏู ฺฉุฑุฏ
ุฏุฑ ุงุจุชุฏุง ุงุฒ ฺฉ ููุทู ุชุตุงุฏู ุดุฑูุน ฺฉุฑุฏู ู ุจู ุณูุช ูุฎุงูู ฺฏุฑุงุฏุงู ู ุฑูู (โฺฏุฑุงุฏุงู ูุฒูู)
ุฏุฑ ูุงูุน ููุทู ุงูุชุฎุงุจ ุดุฏู ุ ููุทู ุง ุจุง ุญุฏุงูุงู ูุงุตูู ุจุง ุณุงุฑ ููุงุท ุงุณุช.

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/sgd.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
</div>

# ุชูุงุจุน ุจุง ุฑุงู ุญู ูุญุงุณุจุงุช

## ุชุงุจุน L2 Loss (Square Loss) โ Mean

ฺฉ ุงุฒ ุชูุงุจุน ุจุณุงุฑ ูพุฑฺฉุงุฑุจุฑุฏ ููุฑุฏ ุงุณุชูุงุฏู ุฏุฑ ุงูฺฏูุฑุชู ูุง ูุซู k-means

### ฺฏุงู ฑ: ูุดุชูโฺฏุฑ ูุณุจุช ุจู $\mu^*$

<div dir="ltr">

$
\frac{dL}{d\mu} = \frac{d}{d\mu} \sum_{i=1}^{n} (x_i - \mu)^2
$

</div>

ุจุง ุงุณุชูุงุฏู ุงุฒ ูุงุนุฏูโ ุฒูุฌุฑูโุง:

$
\frac{dL}{d\mu}
= \sum_{i=1}^{n} \frac{d}{d\mu}(x_i - \mu)^2
= \sum_{i=1}^{n} 2(x_i - \mu)(-1)$

$\frac{dL}{d\mu} = -2\sum_{i=1}^{n} (x_i - \mu)$

---

### ฺฏุงู ฒ: ุจุฑุงุจุฑ ุตูุฑ ูุฑุงุฑ ุฏุงุฏู ูุดุชู (ุดุฑุท ูุงุฒู ุจุฑุง ฺฉููู)

$-2\sum_{i=1}^{n} (x_i - \mu) = 0$

$\sum_{i=1}^{n} (x_i - \mu) = 0$

---

### ฺฏุงู ณ: ุญู ุจุฑุง $\mu^*$

$\sum_{i=1}^{n} x_i - \sum_{i=1}^{n} \mu = 0$

$\sum_{i=1}^{n} x_i - n\mu = 0$

$\mu^* = \frac{1}{n}\sum_{i=1}^{n} x_i$

---

# ูพุงุฏู ุณุงุฒ ุฎูุดู ุจูุฏ ุจุง ุงุณุชูุงุฏู ุงุฒ ุชูุงุจุน ุถุฑุฑ ูุฎุชูู

## ููุฏ ฺฉุฑุฏู ฺฉุชุงุจุฎุงูู ูุง ููุฑุฏ ุงุณุชูุงุฏู :

```python
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import os
import numpy as np
from scipy.optimize import minimize
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tqdm import tqdm
```

## ููุฏ ฺฉุฑุฏู ูุฏู vgg16 ุจุฑุง ุงุณุชุฎุฑุงุฌ ูฺฺฏ

```python
#pre-trained VGG16 model
vgg16 = models.vgg16(pretrained=True)
model = nn.Sequential(*list(vgg16.features.children()))
model.eval()
image preprocessing
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```

## ุงุณุฎุฑุงุฌ ูฺฺฏ ุงุฒ ูุฌููุนู ุฏุงุฏู

ุฏุฑ ุงู ูุณูุช ุงุฒ ุนฺฉุณ ูุง ููุฌูุฏ ุฏุฑ ุฏุชุงุณุช ุ ุงุณุชุฎุฑุงุฌ ูฺฺฏ ุงูุฌุงู ู ุฏูู.

```python
def extract_features(img_path, model, device='cpu'):
    image = Image.open(img_path).convert("RGB")
    input_tensor = preprocess(image).unsqueeze(0).to(device)
    with torch.no_grad():
        features = model(input_tensor)
    # Global average pooling
    global_pooled = torch.mean(features, dim=(2, 3))
    return global_pooled.squeeze().cpu().numpy()
def extract_features_from_folder(folder_path, model, device):
    features_dict = {}
    image_files = [f for f in os.listdir(folder_path)
                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    image_files.sort()
    print(f"Found {len(image_files)} images in '{folder_path}'")
    for file in image_files:
        img_path = os.path.join(folder_path, file)
        print(f"  Extracting features from: {file}")
        features = extract_features(img_path, model, device)
        features_dict[file] = features
    return features_dict, image_files
image_folder = "folder name"
features_dict, image_files = extract_features_from_folder(image_folder, model)
features_list = list(features_dict.values())
data = np.stack(features_list)
```

## ุชุนุฑู ุชูุงุจุน ุถุฑุฑ ุฏุฑ ฺฉุฏ

ุฏุฑ ุงู ูุณูุช ฺฉ ุชุงุจุน ฺฉู ุชุนุฑู ูฺฉูู ฺฉู ุจู ุนููุงู ูุฑูุฏ ุงุณู ุชุงุจุน ุฑุง ฺฏุฑูุชู ู ูุฑููู ุขู ุฑุง ุจุฑ ู ฺฏุฑุฏุงูู

```python

def get_loss_func(loss_type, params={}):
    if loss_type == 'square':

        def loss(x, mu):
            return np.sum((x - mu)**2)
        return loss

    elif loss_type == 'absolute':

        def loss(x, mu):
            return np.sum(np.abs(x - mu))
        return loss

    elif loss_type == 'huber':

        delta = params.get('delta', 1.0)
        def loss(x, mu):
            res = np.abs(x - mu)
            return np.sum(np.where(res <= delta,
                                   0.5 * res**2,
                                   delta * (res - 0.5 * delta)))
        return loss

    elif loss_type == 'pseudo_huber':

        delta = params.get('delta', 1.0)
        def loss(x, mu):
            res = x - mu
            return np.sum(delta**2 * (np.sqrt(1 + (res / delta)**2) - 1))
        return loss
    elif loss_type == 'correntropy':
        sigma = params.get('sigma', 1.0)
        def loss(x, mu):
            d2 = np.sum((x - mu)**2)
            return 1 - np.exp(-d2 / (2 * sigma**2))
        return loss
    elif loss_type == 'epsilon_insensitive':
        epsilon = params.get('epsilon', 1.0)
        def loss(x, mu):
            d = np.linalg.norm(x - mu)
            return max(0, d - epsilon)
        return loss

```

# ุงูฺฏูุฑุชู ุฎูุดู ุจูุฏ

ุจุฑุง ุขุดูุง ุจุดุชุฑ ุจุง ุฎูุดู ุจูุฏ ู ุฑูุด ูุง ุขู ุจู ููฺฉ ุฒุฑ ูุฑุงุญุนู ฺฉูุฏ :

<a href="https://laboratorypatternrecognition.github.io/PatternRecognition_S/PR/Clustering/Clustering_1.html">ููุฏูุงุช ุฎูุดู ุจูุฏ ู ูุฑูููู ฺฉุฑุฏู ูุณุฆูู</a>

<a href="https://laboratorypatternrecognition.github.io/PatternRecognition_S/PR/Clustering/Clustering_1.html">ูุฑุงุญู ุฎูุดูู ุจูุฏ ู ุงุณุชูุงุฏู ุงุฒ ุชูุงุจุน ุถุฑุฑ ูุฎุชูู</a>

## ูพุงุฏู ุณุงุฒ

```python

def update_center(points, loss_type, params):
    if len(points) == 0:
        return np.zeros(points.shape[1])
    if loss_type == 'square':
        return np.mean(points, axis=0)
    elif loss_type == 'absolute':
        return np.median(points, axis=0)
    else:
        def objective(mu):
            loss_func = get_loss_func(loss_type, params)
            total_loss = sum(loss_func(x, mu) for x in points)
            return total_loss

        initial_guess = np.mean(points, axis=0)
        result = minimize(
            objective,
            initial_guess,
            method='BFGS',
            options={'maxiter': 20}
        )
        return result.x
```

```python

def generalized_clustering(data, k, loss_type, params={}, max_iter=3, tol=1e-4):
    n, d = data.shape
    centers = data[np.random.choice(n, k, replace=False)]
    prev_shift = np.inf
    for iter in range(max_iter):
        # Assign each point to nearest center
        dists = np.array([[get_loss_func(loss_type, params)(data[i], centers[j])
                          for j in range(k)]
                         for i in range(n)])
        labels = np.argmin(dists, axis=1)

        #  Update centers
        new_centers = np.zeros((k, d))
        for j in tqdm(range(k), desc=f"Updating centers (iter {iter+1})"):
            points_j = data[labels == j]
            if len(points_j) > 0:
                new_centers[j] = update_center(points_j, loss_type, params)
        # Check convergence
        shift = np.sum(np.linalg.norm(new_centers - centers, axis=1))
        centers = new_centers
        if shift < tol or abs(shift - prev_shift) < 1e-6:
            print(f"  Converged after {iter+1} iterations")
            break
        prev_shift = shift
    return centers, labels

```

```python
def find_closest_image(center, points, indices, loss_func):
    min_dist = np.inf
    closest_idx = -1
    for idx, p in zip(indices, points):
        dist = loss_func(p, center)
        if dist < min_dist:
            min_dist = dist
            closest_idx = idx
    return closest_idx


def plot_representatives(loss_type, centers, labels, image_files, folder_path, loss_func):
    fig, axs = plt.subplots(1, len(centers), figsize=(5 * len(centers), 5))
    fig.suptitle(f'Representative Images - {loss_type.upper()} Loss', fontsize=16, fontweight='bold')
    for j, center in enumerate(centers):
        # Find all images in this cluster
        cluster_indices = [i for i in range(len(labels)) if labels[i] == j]
        cluster_points = data[cluster_indices]
        if len(cluster_points) > 0:
            # Find the image closest to the center
            closest_i = find_closest_image(center, cluster_points, cluster_indices, loss_func)
            img_file = image_files[closest_i]
            img_path = os.path.join(folder_path, img_file)
            img = mpimg.imread(img_path)
            if len(centers) == 1:
                axs.imshow(img)
                axs.set_title(f'Representative {j+1}\n{img_file}', fontsize=12)
                axs.axis('off')
            else:
                axs[j].imshow(img)
                axs[j].set_title(f'Representative {j+1}\n{img_file}', fontsize=12)
                axs[j].axis('off')
    plt.tight_layout()
    plt.show()

```

# ูุชุงุฌ ุฎูุดู ุจูุฏ

ุฏุฑ ุงู ุจุฎุด ุจู ุจุฑุฑุณ ูุชุงุฌ ุฎูุดู ุจูุฏ ุจุง ุงุณุชูุงุฏู ุงุฒ ุชูุงุจุน ุถุฑุฑ ูุฎุชูู ู ูพุฑุฏุงุฒู

### ุชุงุจุน L2

```python

loss_type = 'square'
params = params_dict[loss_type]
z=(f"๐ Running clustering with {loss_type.upper()} loss...")
centers, labels = generalized_clustering(data, k, loss_type, params)
loss_func = get_loss_func(loss_type, params)
plot_representatives(loss_type, centers, labels, image_files, image_folder, loss_func,z)

```

<!-- <div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/SQUARE loss.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ุญุงุตู ุฎูุดู ุจูุฏ ุจุง ุชุงุจุน ุถุฑุฑ L2 ู ููุงุด 3 ูุฑฺฉุฒ ุฎูุดู ุจุฑุชุฑ
</div> -->
<!--  -->

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/SQUARE loss.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/square loss_pca.png" alt="IPS2" style="width: 35%; height: 35%; object-fit: contain;">
</div>

<div class="caption" style="text-align: center; margin-top: 8px;">
    ุญุงุตู ุฎูุดู ุจูุฏ ุจุง ุชุงุจุน ุถุฑุฑ L2 ู ููุงุด 3 ูุฑฺฉุฒ ุฎูุดู ุจุฑุชุฑ ุจู ููุฑุงู ููุงุด ุขู ูุง ุฏุฑ 2 ุจุนุฏ
</div>


### ุชุงุจุน L1

```python
loss_type = 'absolute'
params = params_dict[loss_type]
z=(f"๐ Running clustering with {loss_type.upper()} loss...")
centers, labels = generalized_clustering(data, k, loss_type, params)
loss_func = get_loss_func(loss_type, params)
plot_representatives(loss_type, centers, labels, image_files, image_folder, loss_func,z)

```

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/ABSOLUTE loss.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/L1 loss_pca.png" alt="IPS1" style="width: 35%; height: 35%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
    ุญุงุตู ุฎูุดู ุจูุฏ ุจุง ุชุงุจุน ุถุฑุฑ L1 ู ููุงุด 3 ูุฑฺฉุฒ ุฎูุดู ุจุฑุชุฑ ุจู ููุฑุงู ููุงุด ุขู ูุง ุฏุฑ 2 ุจุนุฏ
</div>
<!--  -->
<!--  -->

### ุชุงุจุน Huber

```python
loss_type = 'huber'
params = params_dict[loss_type]

z=(f"๐ Running clustering with {loss_type.upper()} loss...")
centers, labels = generalized_clustering(data, k, loss_type, params)
loss_func = get_loss_func(loss_type, params)
plot_representatives(loss_type, centers, labels, image_files, image_folder, loss_func,z)
```

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/HUBER loss.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/HUBER  loss_pca.png" alt="IPS1" style="width: 35%; height: 35%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ุญุงุตู ุฎูุดู ุจูุฏ ุจุง ุชุงุจุน ุถุฑุฑ huber ู ููุงุด 3 ูุฑฺฉุฒ ุฎูุดู ุจุฑุชุฑ  ุจู ููุฑุงู ููุงุด ุขู ูุง ุฏุฑ 2 ุจุนุฏ
</div>

### ุชุงุจุน Pseudo-Huber

```python
loss_type = 'pseudo-huber'
params = params_dict[loss_type]
z=(f"๐ Running clustering with {loss_type.upper()} loss...")
centers, labels = generalized_clustering(data, k, loss_type, params)
loss_func = get_loss_func(loss_type, params)
plot_representatives(loss_type, centers, labels, image_files, image_folder, loss_func,z)

```

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/PSEUDO_HUBER loss.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/PSEUDO HUBER   loss_pca.png" alt="IPS1" style="width: 35%; height: 35%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ุญุงุตู ุฎูุดู ุจูุฏ ุจุง ุชุงุจุน ุถุฑุฑ pseudo-huber ู ููุงุด 3 ูุฑฺฉุฒ ุฎูุดู ุจุฑุชุฑ ุจู ููุฑุงู ููุงุด ุขู ูุง ุฏุฑ 2 ุจุนุฏ
</div>

### ุชุงุจุน Correntropy

```python

loss_type = 'correntropy'
params = params_dict[loss_type]

z=(f"๐ Running clustering with {loss_type.upper()} loss...")
centers, labels = generalized_clustering(data, k, loss_type, params)
loss_func = get_loss_func(loss_type, params)
plot_representatives(loss_type, centers, labels, image_files, image_folder, loss_func,z)
```

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/CORRENTROPY loss.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/correntropy   loss_pca.png" alt="IPS1" style="width: 35%; height: 35%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ุญุงุตู ุฎูุดู ุจูุฏ ุจุง ุชุงุจุน ุถุฑุฑ Correntropy ู ููุงุด 3 ูุฑฺฉุฒ ุฎูุดู ุจุฑุชุฑ ุจู ููุฑุงู ููุงุด ุขู ูุง ุฏุฑ 2 ุจุนุฏ
</div>

### ุชุงุจุน Epsilon-Insensitive

```python

loss_type = 'epsilon_insensitive'
params = params_dict[loss_type]

z=(f"๐ Running clustering with {loss_type.upper()} loss...")
centers, labels = generalized_clustering(data, k, loss_type, params)
loss_func = get_loss_func(loss_type, params)
plot_representatives(loss_type, centers, labels, image_files, image_folder, loss_func,z)

```

<div style="display: flex; justify-content: center; align-items: center; gap: 10px;">
    <img src="/assets/patterneffort/ImageCluster/EPSILON_INSENSITIVE loss.png" alt="IPS1" style="width: 50%; height: 50%; object-fit: contain;">
    <img src="/assets/patterneffort/ImageCluster/epsilon_insensitive   loss_pca.png" alt="IPS1" style="width: 35%; height: 35%; object-fit: contain;">
</div>
<div class="caption" style="text-align: center; margin-top: 8px;">
ุญุงุตู ุฎูุดู ุจูุฏ ุจุง ุชุงุจุน ุถุฑุฑ huber ู ููุงุด 3 ูุฑฺฉุฒ ุฎูุดู ุจุฑุชุฑุจู ููุฑุงู ููุงุด ุขู ูุง ุฏุฑ 2 ุจุนุฏ
</div>

## ูุชุงุฌ

ุฏุฑ ุจุฎุด ูุชุงุฌุ ุจุง ููุงุด ุชุตุงูุฑ ููุงูุฏูโ ูุฑ ุฎูุดู ุจุฑุง ุชูุงุจุน ุถุฑุฑ ูุฎุชููุ ูโุชูุงูู ุจูโุตูุฑุช ุดููุฏ ุจุจูู ฺฉู ุดุจฺฉูโ VGG16 ฺู ุณุงุฎุชุงุฑ ุฑุง ุฏุฑ ูุถุง ูฺฺฏโูุง ุขููุฎุชู ุงุณุช. ูุฑ ุชุตูุฑ ฺฉู ุจูโุนููุงู ยซูุฑฺฉุฒ ุฎูุดูยป ููุงุด ุฏุงุฏู ูโุดูุฏุ ุฏุฑ ูุงูุน ูููููโุง ุงุณุช ฺฉู ฺฉูุชุฑู ูุงุตูู ุฑุง ุจุง ุณุงุฑ ุชุตุงูุฑ ุขู ุฎูุดู ุฏุฑ ูุถุง ูฺฺฏ ุฏุงุฑุฏ ู ูโุชูุงู ุขู ุฑุง ููุงูุฏูโ ุจุตุฑ ุขู ฺฏุฑูู ุฏุงูุณุช. ุฒูุงู ฺฉู ฺฉ ุชุตูุฑ ุฏุฑ ฺูุฏ ุชุงุจุน ุถุฑุฑ ูุฎุชูู ุจูโุนููุงู ูุฑฺฉุฒ ุฎูุดู ุชฺฉุฑุงุฑ ูโุดูุฏุ ุงู ููุถูุน ูุดุงู ูโุฏูุฏ ฺฉู ุขู ููููู ุฏุฑ ูุถุง ูฺฺฏโูุง ฺฉ ูููููโ ูพุงุฏุงุฑ ู ูุณุชูู ุงุฒ ุฌุฒุฆุงุช ุงูุชุฎุงุจ ุชุงุจุน ุถุฑุฑุ ุณุงุฎุชุงุฑ ฺฉู ุฎูุดูโูุง ุญูู ุขู ุดฺฉู ูโฺฏุฑุฏ. ุงุฒ ุทุฑู ุฏฺฏุฑุ ุชูุงูุช ุจู ุชุตุงูุฑ ููุงูุฏู ุฏุฑ ุชูุงุจุน ุถุฑุฑ ูุฎุชูู ุจุงูฺฏุฑ ุงู ุงุณุช ฺฉู ูุญููโ ุงูุฏุงุฒูโฺฏุฑ ูุงุตูู ู ุฎุทุง ูโุชูุงูุฏ ุจุฑ ูุฑุฒุจูุฏ ุฎูุดูโูุง ุงุซุฑ ุจฺฏุฐุงุฑุฏุ ูุฑฺูุฏ ูุญุชูุง ฺฉู ุฎูุดูโูุง (ูุซูุงู ููุน ุญูุงู ุง ุฒุงููโ ุฏุฏ) ูุนูููุงู ุซุงุจุช ูโูุงูุฏ. ุจู ุงู ุชุฑุชุจุ ูุดุงูุฏูโ ูุณุชูู ูุฑุงฺฉุฒ ุฎูุดู ฺฉูฺฉ ูโฺฉูุฏ ุชุง ุนูุงูู ุจุฑ ุชุญูู ุนุฏุฏุ ุฏุฑฺฉ ุดููุฏ ู ุจุตุฑ ุจูุชุฑ ุงุฒ ฺฉูุช ุฎูุดูโุจูุฏ ู ูุนูุง ูุฑ ุฎูุดู ุฏุฑ ุณุทุญ ุชุตูุฑ ุจูโุฏุณุช ุขูุฑู.

# ููุงุจุน

- http://cnnlocalization.csail.mit.edu/
- https://docs.pytorch.org/vision/main/models.html
- https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html
- https://arxiv.org/abs/1409.1556
